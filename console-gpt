#!venv/bin/python
# uses: openai 1.10.0, colorama 0.4.6

# import modules
import argparse
import platform
import time
from openai import OpenAI
from colorama import Fore, Style

# define the model settings
system_prompt = f"Reply briefly as an expert in {platform.system()} {platform.release()}"
TOKENS = 200
TEMPERATURE = 1
MODEL = "gpt-3.5-turbo"

# function to generate a chat completion using the OpenAI API
def chat_completion(
    _system_prompt=system_prompt,
    _user_prompt=None,
    _tokens=TOKENS,
    _model=MODEL,
    _temperature=TEMPERATURE
    ):

    client = OpenAI()
    messages = [
        {"role": "system", "content": _system_prompt},
        {"role": "user", "content": _user_prompt},
    ]

    response = client.chat.completions.create(
        temperature=_temperature,
        max_tokens=_tokens,
        model=_model,
        messages=messages
    )

    content = response.choices[0].message.content
    completion_tokens = response.usage.completion_tokens
    prompt_tokens = response.usage.prompt_tokens
    total_tokens = response.usage.total_tokens

    return {
        "content": content,
        "completion_tokens": completion_tokens,
        "prompt_tokens": prompt_tokens,
        "total_tokens": total_tokens
    }

# main entry point to script
if __name__ == "__main__":
    # setup argparse and assign default values
    parser = argparse.ArgumentParser()
    parser.add_argument("prompt", type=str)
    args = parser.parse_args()

    response = chat_completion(_user_prompt=args.prompt)
    reply = response["content"]
    print(f"ðŸ¤– {Fore.CYAN}", end="")
    for char in reply:
        print(char, end="", flush=True)
        time.sleep(0.005)
    print(f"{Style.RESET_ALL}")