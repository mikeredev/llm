#!/home/mishi/.config/llm/venv/bin/python
# uses: [anthropic] colorama 0.4.6

# import modules
import argparse
import platform
import time
import sys
sys.path.append('/home/mishi/.config/llm')
from modules import anthropic
from colorama import Fore, Style

# define the request parameters
SYSTEM_PROMPT = f"Concisely execute the grokked user instruction."
MAX_TOKENS = 200
TEMPERATURE = 1
MODEL = "claude-3-haiku-20240307"
#MODEL = "claude-3-opus-20240229"

# main entry point to script
if __name__ == "__main__":
    # setup argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("prompt", type=str, help="enter your query")
    parser.add_argument("--tokens", type=int, default=MAX_TOKENS, help="maximum number of tokens to generate")
    parser.add_argument("--temp", type=float, default=TEMPERATURE, help="set temperature of response")
    parser.add_argument("--model", type=str, default=MODEL, help="specify the language model to use")
    args = parser.parse_args()

    # instantiate the new completion object
    chat = anthropic.Completion()

    # generate chat completion from user input
    response = chat.generate(
        _system_prompt=SYSTEM_PROMPT,
        _user_prompt=args.prompt,
        _max_tokens=args.tokens,
        _temperature=args.temp,
        _model=args.model)
    reply = response["content"]

    # print output to console
    print(f"ðŸ¤– {Fore.CYAN}", end="")
    for char in reply:
        print(char, end="", flush=True)
        time.sleep(0.005)
    print(f"{Style.RESET_ALL}")
