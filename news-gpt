#!venv/bin/python
# uses: feedparser 6.0.11, openai 1.10.0

# import modules
import feedparser
from openai import OpenAI
import subprocess
import sys

# define how many items to return from which feed
FEED_URL = "https://feeds.bbci.co.uk/news/world/rss.xml"
FEED_SIZE = 5

# define request parameters
SYSTEM_PROMPT = f"Please summarize these news items in {FEED_SIZE} succinct bullet-points."
TOKENS = 200
MODEL = "gpt-3.5-turbo"
TEMPERATURE = 0.3


# function to parse the RSS feed and return a list of items
def feedreader():
    feed = feedparser.parse(FEED_URL)

    items = []
    for index, feed_entry in enumerate(feed.entries[:(FEED_SIZE)], start=1):
        last_item = f"{index} {feed_entry['title']}: {feed_entry['summary']}"
        items.append(last_item)


# function to generate a chat completion using the OpenAI API
def chat_completion(
    _system_prompt=SYSTEM_PROMPT,
    _user_prompt=None,
    _tokens=TOKENS,
    _model=MODEL,
    _temperature=TEMPERATURE):
    client = OpenAI()

    messages = [
        {"role": "system", "content": _system_prompt},
        {"role": "user", "content": _user_prompt},
    ]

    response = client.chat.completions.create(
        temperature=_temperature,
        max_tokens=_tokens,
        model=_model,
        messages=messages
    )

    content = response.choices[0].message.content
    completion_tokens = response.usage.completion_tokens
    prompt_tokens = response.usage.prompt_tokens
    total_tokens = response.usage.total_tokens

    return {
        "content": content,
        "completion_tokens": completion_tokens,
        "prompt_tokens": prompt_tokens,
        "total_tokens": total_tokens
    }


# script entry point
if __name__ == "__main__":
    # set the user prompt to a string containing the returned RSS items
    user_prompt = str(feedreader())
    # generate the completion and send a notification
    response = chat_completion(
        _system_prompt=SYSTEM_PROMPT,
        _user_prompt=user_prompt,
        _tokens=TOKENS,
        _temperature=TEMPERATURE,
        _model=MODEL
    )
    output = response["content"]
    subprocess.run(["dunstify", "-a", "news-gpt", "--", "Today's news", f"{output}"])
